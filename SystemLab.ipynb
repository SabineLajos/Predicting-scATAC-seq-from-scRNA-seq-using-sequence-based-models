{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.sparse import csc_matrix\n",
    "import logging\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = {\n",
    "    'input_train_mod2': '/mnt/data/output/datasets/common/openproblems_bmmc_multiome_phase2/openproblems_bmmc_multiome_phase2.manual_formatting.output_mod2.h5ad',\n",
    "    'input_train_mod1': '/mnt/data/output/datasets/common/openproblems_bmmc_multiome_phase2/openproblems_bmmc_multiome_phase2.manual_formatting.output_rna.h5ad',\n",
    "    'input_test_mod2': '/mnt/data/output/datasets/predict_modality/openproblems_bmmc_multiome_phase2_mod2/openproblems_bmmc_multiome_phase2_mod2.censor_dataset.output_test_mod1.h5ad',\n",
    "    'input_test_mod1': '/mnt/data/output/datasets/predict_modality/openproblems_bmmc_multiome_phase2_mod2/openproblems_bmmc_multiome_phase2_mod2.censor_dataset.output_test_mod2.h5ad',\n",
    "    'output': 'output.h5ad',\n",
    "}\n",
    "meta = { 'functionality_name': 'lslab' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"gex2atac\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_mod1 = ad.read_h5ad(par['input_train_mod1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_mod2 = ad.read_h5ad(par['input_train_mod2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_mod2= input_train_mod2[input_train_mod2.obs[\"is_train\"]==False]\n",
    "\n",
    "input_test_mod1= input_train_mod1[input_train_mod1.obs[\"is_train\"]==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test_mod1=input_test_mod1[0:20000:2]\n",
    "input_test_mod2=input_test_mod2[0:20000:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train_mod2= input_train_mod2[input_train_mod2.obs[\"is_train\"]==True]\n",
    "\n",
    "input_train_mod1= input_train_mod1[input_train_mod1.obs[\"is_train\"]==True] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = set(input_train_mod1.obs[\"batch\"])\n",
    "batch_dict = {batch:i for i, batch in enumerate(batches)}\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(input_train_mod1.n_obs):\n",
    "    y.append(int(batch_dict[input_train_mod1.obs[\"batch\"][i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_train_mod1.obs\n",
    "batches = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_train_mod1 = input_train_mod1.copy()\n",
    "inp_train_mod2 = input_train_mod2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1, out2 = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"atac2gex\" in dataset_id:\n",
    "    out_knn = 0\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        print(fold)\n",
    "        fold += 1\n",
    "\n",
    "        input_test_mod1 = inp_train_mod1[test_index, :]\n",
    "        true_test_mod2 = inp_train_mod2[test_index, :]\n",
    "\n",
    "        input_train_mod1 = inp_train_mod1[train_index, :]\n",
    "        input_train_mod2 = inp_train_mod2[train_index, :]\n",
    "    \n",
    "        input_mod1 = ad.concat(\n",
    "                {\"train\": input_train_mod1, \"val\": input_test_mod1, \"test\": final_input_test_mod1},\n",
    "                axis=0,\n",
    "                join=\"outer\",\n",
    "                label=\"group\",\n",
    "                fill_value=0,\n",
    "                index_unique=\"-\",\n",
    "            )\n",
    "\n",
    "        # Do PCA on the input data\n",
    "        logging.info('Performing dimensionality reduction on modality 1 values...')\n",
    "        embedder_mod1 = TruncatedSVD(n_components=50)\n",
    "        mod1_pca = embedder_mod1.fit_transform(input_mod1.X)\n",
    "\n",
    "        logging.info('Performing dimensionality reduction on modality 2 values...')\n",
    "        embedder_mod2 = TruncatedSVD(n_components=50)\n",
    "        mod2_pca = embedder_mod2.fit_transform(input_train_mod2.X)\n",
    "\n",
    "        # split dimred back up\n",
    "        X_train = mod1_pca[input_mod1.obs['group'] == 'train']\n",
    "        X_test = mod1_pca[input_mod1.obs['group'] == 'test']\n",
    "        y_train = mod2_pca\n",
    "\n",
    "        # Get all responses of the training data set to fit the\n",
    "        # KNN regressor later on.\n",
    "        # Make sure to use `toarray()` because the output might\n",
    "        # be sparse and `KNeighborsRegressor` cannot handle it.\n",
    "\n",
    "        logging.info('Running Linear regression...')\n",
    "    \n",
    "        reg = KNeighborsRegressor(n_neighbors=25, metric='minkowski')\n",
    "\n",
    "        # Train the model on the PCA reduced modality 1 and 2 data\n",
    "        reg.fit(X_train, y_train)\n",
    "        y_pred = reg.predict(X_test)\n",
    "\n",
    "        # Project the predictions back to the modality 2 feature space\n",
    "        y_pred = y_pred @ embedder_mod2.components_\n",
    "    \n",
    "        out_knn += y_pred\n",
    "\n",
    "    y_pred_knn = out_knn / 10\n",
    "    \n",
    "    out_rf = 0\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        print(fold)\n",
    "        fold += 1\n",
    "\n",
    "        input_test_mod1 = inp_train_mod1[test_index, :]\n",
    "        input_test_mod2 = inp_train_mod2[test_index, :]\n",
    "\n",
    "        input_train_mod1 = inp_train_mod1[train_index, :]\n",
    "        input_train_mod2 = inp_train_mod2[train_index, :]\n",
    "    \n",
    "        input_mod1 = ad.concat(\n",
    "                {\"train\": input_train_mod1, \"val\": input_val_mod1, \"test\": final_input_test_mod1},\n",
    "                axis=0,\n",
    "                join=\"outer\",\n",
    "                label=\"group\",\n",
    "                fill_value=0,\n",
    "                index_unique=\"-\",\n",
    "            )\n",
    "\n",
    "        # Do PCA on the input data\n",
    "        logging.info('Performing dimensionality reduction on modality 1 values...')\n",
    "        embedder_mod1 = TruncatedSVD(n_components=50)\n",
    "        mod1_pca = embedder_mod1.fit_transform(input_mod1.X)\n",
    "\n",
    "        logging.info('Performing dimensionality reduction on modality 2 values...')\n",
    "        embedder_mod2 = TruncatedSVD(n_components=50)\n",
    "        mod2_pca = embedder_mod2.fit_transform(input_train_mod2.X)\n",
    "\n",
    "        # split dimred back up\n",
    "        X_train = mod1_pca[input_mod1.obs['group'] == 'train']\n",
    "        X_test = mod1_pca[input_mod1.obs['group'] == 'test']\n",
    "        y_train = mod2_pca\n",
    "\n",
    "        # Get all responses of the training data set to fit the\n",
    "        # KNN regressor later on.\n",
    "        # Make sure to use `toarray()` because the output might\n",
    "        # be sparse and `KNeighborsRegressor` cannot handle it.\n",
    "\n",
    "        logging.info('Running Linear regression...')\n",
    "    \n",
    "        reg = RandomForestRegressor()\n",
    "\n",
    "        # Train the model on the PCA reduced modality 1 and 2 data\n",
    "        reg.fit(X_train, y_train)\n",
    "        y_pred = reg.predict(X_test)\n",
    "\n",
    "        # Project the predictions back to the modality 2 feature space\n",
    "        y_pred = y_pred @ embedder_mod2.components_\n",
    "    \n",
    "        out_rf += y_pred\n",
    "\n",
    "    y_pred_rf = out_rf / 10\n",
    "    \n",
    "    y_pred = 0.45 * y_pred_rf + 0.55 * y_pred_knn\n",
    "    y_pred = csc_matrix(y_pred)\n",
    "\n",
    "    adata = ad.AnnData(\n",
    "        X=y_pred,\n",
    "       obs=final_input_test_mod1.obs,\n",
    "       var=inp_train_mod2.var,\n",
    "       uns={\n",
    "           'dataset_id': dataset_id,\n",
    "           'method_id': meta[\"functionality_name\"],\n",
    "       },\n",
    "    )\n",
    "    \n",
    "    logging.info('Storing annotated data...')\n",
    "    adata.write_h5ad(par['output'], compression = \"gzip\")\n",
    "else:\n",
    "    out_knn = 0\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        print(fold)\n",
    "        fold += 1\n",
    "\n",
    "        input_val_mod1 = inp_train_mod1[test_index, :]\n",
    "        input_val_mod2 = inp_train_mod2[test_index, :]\n",
    "\n",
    "        input_train_mod1 = inp_train_mod1[train_index, :]\n",
    "        input_train_mod2 = inp_train_mod2[train_index, :]\n",
    "    \n",
    "        input_mod1 = ad.concat(\n",
    "                {\"train\": input_train_mod1, \"val\": input_val_mod1, \"test\": input_test_mod1},\n",
    "                axis=0,\n",
    "                join=\"outer\",\n",
    "                label=\"group\",\n",
    "                fill_value=0,\n",
    "                index_unique=\"-\",\n",
    "            )\n",
    "\n",
    "        # Do PCA on the input data\n",
    "        logging.info('Performing dimensionality reduction on modality 1 values...')\n",
    "        embedder_mod1 = TruncatedSVD(n_components=50)\n",
    "        mod1_pca = embedder_mod1.fit_transform(input_mod1.X)\n",
    "\n",
    "        logging.info('Performing dimensionality reduction on modality 2 values...')\n",
    "        embedder_mod2 = TruncatedSVD(n_components=50)\n",
    "        mod2_pca = embedder_mod2.fit_transform(input_train_mod2.X)\n",
    "\n",
    "        # split dimred back up\n",
    "        X_train = mod1_pca[input_mod1.obs['group'] == 'train']\n",
    "        X_test = mod1_pca[input_mod1.obs['group'] == 'test']\n",
    "        y_train = mod2_pca\n",
    "\n",
    "        # Get all responses of the training data set to fit the\n",
    "        # KNN regressor later on.\n",
    "        # Make sure to use `toarray()` because the output might\n",
    "        # be sparse and `KNeighborsRegressor` cannot handle it.\n",
    "\n",
    "        logging.info('Running Linear regression...')\n",
    "    \n",
    "        reg = KNeighborsRegressor(n_neighbors=25, metric='minkowski')\n",
    "\n",
    "        # Train the model on the PCA reduced modality 1 and 2 data\n",
    "        reg.fit(X_train, y_train)\n",
    "        y_pred = reg.predict(X_test)\n",
    "\n",
    "        # Project the predictions back to the modality 2 feature space\n",
    "        y_pred = y_pred @ embedder_mod2.components_\n",
    "    \n",
    "        out_knn += y_pred\n",
    "\n",
    "    y_pred = out_knn / 10\n",
    "    y_pred = csc_matrix(y_pred)\n",
    "\n",
    "    adata = ad.AnnData(\n",
    "        X=y_pred,\n",
    "       obs=input_test_mod1.obs,\n",
    "       var=inp_train_mod2.var,\n",
    "       uns={\n",
    "           'dataset_id': dataset_id,\n",
    "           'method_id': meta[\"functionality_name\"],\n",
    "       },\n",
    "    )\n",
    "    \n",
    "    logging.info('Storing annotated data...')\n",
    "    adata.write_h5ad(par['output'], compression = \"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision,recall,_ = sklearn.metrics.precision_recall_curve(np.reshape(np.array(input_test_mod2.X.todense()), -1), \n",
    "                                                            np.reshape(np.array(adata.X.todense()), -1))                                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.PrecisionRecallDisplay(precision=precision, recall=recall).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUPRC = sklearn.metrics.average_precision_score(np.reshape(np.array(input_test_mod2.X.todense()), -1),\n",
    "                                                np.reshape(np.array(adata.X.todense()), -1))\n",
    "AUPRC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.array(adata.X.todense()) - np.array(input_test_mod2.X.todense())\n",
    "n,m = adata.shape\n",
    "RMSE = np.sqrt(1/(n * m) * (diff **2).sum())\n",
    "RMSE"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78c310f1ae02813f0a767dc6ed9b6ac3715ca34f14905f9884f9826e838bd0e1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
