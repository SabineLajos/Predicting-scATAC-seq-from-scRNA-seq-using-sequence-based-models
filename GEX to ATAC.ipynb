{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "import pytorch_lightning as pl\n",
    "import tensorboard\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "from scvi.nn import Encoder\n",
    "from scvi.module._peakvae import Decoder\n",
    "from scvi.dataloaders import DataSplitter\n",
    "from scvi.dataloaders._ann_dataloader import AnnDataLoader\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"Sabine\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if user == \"Tobi\":\n",
    "    data_path = 'C:/Users/Tobias/Desktop/Single Cell Data/Full/phase2-private-data/common/openproblems_bmmc_multiome_phase2'\n",
    "if user == \"Sabine\":\n",
    "    data_path = \"/mnt/data/output/datasets/common/openproblems_bmmc_multiome_phase2\"\n",
    "    \n",
    "only_train = True\n",
    "\n",
    "adata = sc.read_h5ad(os.path.join(data_path, \"openproblems_bmmc_multiome_phase2.manual_formatting.output_mod2.h5ad\"))\n",
    "gex = sc.read_h5ad(os.path.join(data_path, \"openproblems_bmmc_multiome_phase2.manual_formatting.output_rna.h5ad\"))\n",
    "\n",
    "if only_train == True:\n",
    "    test_adata = adata[adata.obs[\"is_train\"] == False]\n",
    "    test_gex = gex[gex.obs[\"is_train\"] == False]\n",
    "    \n",
    "    adata = adata[adata.obs[\"is_train\"] == True]\n",
    "    gex = gex[gex.obs[\"is_train\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['X_gex'] = gex.layers['counts']\n",
    "test_adata.obsm['X_gex'] = test_gex.layers['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "if user == \"Tobi\":\n",
    "   binding_probs = pd.read_hdf('C:/Users/Tobias/Desktop/Single Cell Data/deepbind_output.h5ad', key = 'ChIP-seq/atac-peaks') \n",
    "if user == \"Sabine\":\n",
    "   binding_probs = pd.read_hdf(\"/mnt/data/output/deepbind/deepbind_output.h5ad\", key = 'ChIP-seq/atac-peaks')\n",
    "\n",
    "TF_names = binding_probs.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binding_probs = torch.tensor(binding_probs.values)\n",
    "binding_probs = torch.sigmoid(binding_probs) #change logits to binding_probs\n",
    "binding_probs.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GexToATAC(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()  \n",
    "        \n",
    "        self.encoder = Encoder(\n",
    "            n_input=13431,\n",
    "            n_layers=hparams[\"n_layers\"],\n",
    "            n_output=hparams[\"latent_dim\"],\n",
    "            n_hidden=hparams[\"n_hidden_encoder\"],\n",
    "            n_cat_list=None,\n",
    "            dropout_rate=0.1,\n",
    "            activation_fn=torch.nn.LeakyReLU,\n",
    "            distribution=\"normal\",\n",
    "            var_eps=0,\n",
    "            use_batch_norm=False,\n",
    "            use_layer_norm=True,\n",
    "        )\n",
    "        \n",
    "        self.bp = nn.Parameter(hparams[\"binding_probabilities\"], requires_grad=False)\n",
    "        self.bias = nn.Parameter(torch.rand(1, self.bp.shape[0]))\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, use_z_mean=False):\n",
    "        qz_m, qz_v, z = self.encoder(x) # giving out mean, std and z because we want to use mean for the latent space\n",
    "        latent = z if not use_z_mean else qz_m\n",
    "#        p = self.decoder(latent)\n",
    "        p = latent @ self.bp.T.float()\n",
    "        p = self.Sigmoid(p + self.bias)\n",
    "        return qz_m, qz_v, z, p\n",
    "\n",
    "    def general_step(self, batch, batch_idx):\n",
    "        x = batch.get(\"X_gex\")\n",
    "        y = batch.get(\"X\")\n",
    "        qz_m, qz_v, z, p = self.forward(x)\n",
    "        bce = torch.nn.BCELoss(reduction=\"none\")(p, y.float()).sum(dim=-1).sum()\n",
    "        #qz_v is the variance with qz_v = sigma ^2\n",
    "        #sigma = torch.sqrt(qz_v)\n",
    "        kld = kl_divergence(Normal(qz_m, torch.sqrt(qz_v)), Normal(0, 1)).sum(dim=1)\n",
    "        loss = bce.sum() + (kld ).sum()\n",
    "        return loss, bce.sum(), kld.sum()\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, bce, kld = self.general_step(batch, batch_idx)\n",
    "        self.log('loss', loss)\n",
    "        self.log('BCE', bce)\n",
    "        self.log('KLD', kld)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, bce, kld = self.general_step(batch, batch_idx)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_BCE', bce)\n",
    "        self.log('val_KLD', kld)\n",
    "        return {'loss': loss}  \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.Adam(\n",
    "                    self.parameters(),\n",
    "                    lr = hparams[\"lr\"],\n",
    "                    betas=(0.9, 0.999), eps=1e-08, weight_decay=hparams[\"wd\"], amsgrad=False)\n",
    "        return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\"lr\": 5e-4, #1e-3\n",
    "           \"wd\": 1e-4,\n",
    "#           \"klw\": 400,\n",
    "           \"n_layers\": 3,\n",
    "           \"batch_size\": 128,\n",
    "           \"latent_dim\": 136,\n",
    "           \"n_hidden_encoder\": 300, #116, #int(sqrt(gex.shape[1]))\n",
    "#           \"n_hidden_decoder\": 342, #int(sqrt(adata.shape[1]))\n",
    "           \"binding_probabilities\": binding_probs,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2A = GexToATAC(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.data.setup_anndata(adata)\n",
    "scvi.data.register_tensor_from_anndata(\n",
    "            adata,\n",
    "            registry_key='X_gex',\n",
    "            adata_attr_name='obsm',\n",
    "            adata_key_name='X_gex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splitter = DataSplitter(\n",
    "    adata,\n",
    "    train_size=0.9,\n",
    "    validation_size=0.1,\n",
    "    batch_size=hparams[\"batch_size\"],\n",
    "    use_gpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this comand in the ``CMD`` set to the proper directory: ``tensorboard --logdir lightning_logs --port 6005``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "            max_epochs=25,\n",
    "            gpus=1 if torch.cuda.is_available() else None\n",
    "          )\n",
    "\n",
    "G2A.to(device)\n",
    "trainer.fit(G2A,\n",
    "            data_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_checkpoint(\"/mnt/CMSCB/CMSCB/GenEx to ATAC/our_save_dim3.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G2A = GexToATAC.load_from_checkpoint(\"/mnt/CMSCB/CMSCB/GenEx to ATAC/our_save_dim3.ckpt\", hparams = hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = AnnDataLoader(adata, shuffle=False, batch_size=adata.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adata = test_adata[0:20000:2]\n",
    "test_adata = test_adata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi.data.setup_anndata(test_adata)\n",
    "scvi.data.register_tensor_from_anndata(\n",
    "            test_adata,\n",
    "            registry_key='X_gex',\n",
    "            adata_attr_name='obsm',\n",
    "            adata_key_name='X_gex')\n",
    "test_data = AnnDataLoader(test_adata, shuffle=False, batch_size=test_adata.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_data:\n",
    "    G2A.eval()\n",
    "    with torch.no_grad():\n",
    "        _,_,_,p  = G2A(batch.get(\"X_gex\"))\n",
    "        \n",
    "test_adata.obsm[\"predicted_probs\"] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision,recall,_ = sklearn.metrics.precision_recall_curve(np.reshape(np.array(test_adata.X.todense()), -1),\n",
    "                                                            np.reshape(np.array(test_adata.obsm[\"predicted_probs\"]), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.PrecisionRecallDisplay(precision=precision, recall=recall).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUPRC = sklearn.metrics.average_precision_score(np.reshape(np.array(test_adata.X.todense()), -1),\n",
    "                                                np.reshape(np.array(test_adata.obsm[\"predicted_probs\"]), -1))\n",
    "AUPRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUROC=sklearn.metrics.roc_auc_score(np.reshape(np.array(test_adata.X.todense()), -1),\n",
    "                                    np.reshape(np.array(test_adata.obsm[\"predicted_probs\"]), -1))\n",
    "AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.array(test_adata.X.todense()) - np.array(test_adata.obsm[\"predicted_probs\"])\n",
    "n,m = test_adata.shape\n",
    "RMSE = np.sqrt(1/(n * m) * (diff ** 2).sum())\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if our model would always predict 0 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(1/(n * m) * (np.array(test_adata.X.todense()) ** 2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worst possibele RMSE = 1 if we always predinct the opposit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_data:\n",
    "    G2A.eval()\n",
    "    with torch.no_grad():\n",
    "        _,_,latent  = G2A.encoder(batch.get(\"X_gex\"))\n",
    "test_adata.obsm[\"latent\"] = latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embedding(adata, X_emb):\n",
    "            \n",
    "    adata.obsm['X_emb'] = X_emb\n",
    "    \n",
    "    if 'X_umap' in adata.obsm.keys():\n",
    "        adata.obsm.pop('X_umap')\n",
    "    \n",
    "    if 'umap' in adata.obsm.keys():\n",
    "        adata.obsm.pop('umap')\n",
    "        \n",
    "    if 'neighbors' in adata.uns.keys():\n",
    "        adata.uns.pop('neighbors')\n",
    "\n",
    "    sc.pp.neighbors(adata, use_rep='X_emb')\n",
    "    sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Latent Embedding to Cell Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the k-nearest-neighbor graph that is used in both clustering and umap algorithms\n",
    "sc.pp.neighbors(test_adata, use_rep=\"latent\")\n",
    "\n",
    "# compute the umap\n",
    "sc.tl.umap(test_adata, min_dist=0.2)\n",
    "\n",
    "# cluster the space (use a lower resolution to get fewer clusters than the default)\n",
    "sc.tl.leiden(test_adata, key_added=\"our_cluster\", resolution=1)\n",
    "sc.pl.umap(test_adata, color='our_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.adjusted_rand_score(test_adata.obs[\"our_cluster\"], test_adata.obs[\"cell_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional Factor Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_access=np.mean(adata.X, axis=0)\n",
    "test_mean_access=np.mean(test_adata.X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.squeeze(np.array(-np.log((1/mean_access)-1))),\n",
    "            np.squeeze(G2A.bias.detach().numpy()),\n",
    "            s=20, alpha=0.4)\n",
    "\n",
    "plt.title(\"Correlation Region Factor - Average Accessesability\")\n",
    "plt.xlabel(\"Average Accessability in Train Data\")\n",
    "plt.ylabel(\"Region Factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.squeeze(np.array(-np.log((1/test_mean_access)-1))),\n",
    "            np.squeeze(G2A.bias.detach().numpy()),\n",
    "            s=20, alpha=0.4)\n",
    "\n",
    "plt.title(\"Correlation Region Factor - Average Accessesability\")\n",
    "plt.xlabel(\"Average Accessability in Test Data\")\n",
    "plt.ylabel(\"Region Factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(np.squeeze(np.array(-np.log((1/mean_access)-1))),\n",
    "                     np.squeeze(G2A.bias.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(test_mean_access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(np.squeeze(np.array(-np.log((1/(test_mean_access + eps))-1))),\n",
    "                     np.squeeze(G2A.bias.detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added a small offset to mean accessability on test since some peaks are not accessable in the test set leading to 0 average accessability for that peak and thus leading to devision by 0 in the calculation of correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcription Factor Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 136):\n",
    "    string = TF_names[i] + \"-activity\"\n",
    "    test_adata.obs[string[20:]] = test_adata.obsm[\"latent\"][:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_names_array = [None]*136\n",
    "\n",
    "for i in range(0, 136):\n",
    "    string = TF_names[i] + \"-activity\"\n",
    "    TF_names_array[i] = string[20:]\n",
    "\n",
    "TF_names_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_embedding(test_adata, latent)\n",
    "sc.pl.umap(test_adata, color='cell_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(test_adata, color = [\"SPI1-activity\", \"GATA1-activity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(test_adata, color = [\"PAX5-activity\", \"TAL1-activity\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
